{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14345790",
   "metadata": {},
   "source": [
    "### Case Study 3 : Spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c7a97",
   "metadata": {},
   "source": [
    "Submitted by:\n",
    "\n",
    "- Ravi Sivaraman\n",
    "- Balaji Avvaru\n",
    "- Apurv Mittal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffec101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import isfile\n",
    "import email\n",
    "#import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import silhouette_score\n",
    "import hdbscan\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.feature_extraction import text\n",
    "from wordcloud import WordCloud\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f978a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of emails\n",
    "data_path = \"/Users/ravis/Downloads/SpamAssassinMessages\"\n",
    "# get all sub folders\n",
    "sub_folders = [x[0] for x in os.walk(data_path) if x[0] != data_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55127fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "                   \n",
    "# read all emails from all sub folders\n",
    "mail_ty = []\n",
    "text_ty = []\n",
    "data = []\n",
    "target = []\n",
    "email_attachment = []\n",
    "attachment = False\n",
    "\n",
    "for folder in sub_folders:\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    for file in files:\n",
    "        with open(f\"{folder}/{file}\", encoding=\"latin1\") as f:\n",
    "            #    with open(f\"{folder}/{file}\",\"r\") as f:\n",
    "            x = email.message_from_file(f)\n",
    "          #  print(x)\n",
    "    #    if (file != 'cmds'): \n",
    "    #        mail_data.append(lines)\n",
    "            \n",
    "        mail_type = x.get_content_type()\n",
    "        text_type = x.get_content_charset()\n",
    "        mail_ty.append(mail_type)\n",
    "        text_ty.append(text_type)\n",
    "        if re.search(\"spam\", folder):\n",
    "            target.append(1)\n",
    "        else:\n",
    "             target.append(0)\n",
    "                               \n",
    "        if mail_type == \"text/html\":\n",
    "            if not (isinstance(x.get_payload(), str)) and x.get_payload().get('Content-Disposition'):\n",
    "                dispositions = x.get_payload().get(\"Content-Disposition\", None).strip().split(\";\")\n",
    "                if bool(dispositions[0].lower() == \"attachment\"):\n",
    "                    attachment = True\n",
    "                else:\n",
    "                    attachment = False\n",
    "          \n",
    "            tmp = BeautifulSoup(x.get_payload(), 'html.parser')\n",
    "            tmp = tmp.text.replace(\"\\n\", \" \")\n",
    "            data.append(tmp)\n",
    "        elif \"multipart\" in mail_type:\n",
    "            attachment = False\n",
    "            multipart_data = []\n",
    "            for text in x.get_payload():                        \n",
    "                if not isinstance(text, str): \n",
    "                    if text.get('Content-Disposition'):\n",
    "                        dispositions = text.get(\"Content-Disposition\", None).strip().split(\";\")\n",
    "                        if bool(dispositions[0].lower() == \"attachment\"):\n",
    "                            attachment = True\n",
    "                            \n",
    "                    if text.get_content_type() == \"text/html\":\n",
    "                        tmp = BeautifulSoup(text.get_payload(), 'html.parser')\n",
    "                        tmp = tmp.text.replace(\"\\n\", \" \")\n",
    "                        multipart_data.append(tmp)\n",
    "                    elif text.get_content_type() == \"text/plain\":\n",
    "                        multipart_data.append(text.get_payload()) \n",
    "                \n",
    "            multipart_email = [''.join(str(item)) for item in multipart_data]\n",
    "            data.append(multipart_email)\n",
    "        else:\n",
    "            if not (isinstance(x.get_payload(), str)) and x.get_payload().get('Content-Disposition'):\n",
    "                dispositions = x.get_payload().get(\"Content-Disposition\", None).strip().split(\";\")\n",
    "                if bool(dispositions[0].lower() == \"attachment\"):\n",
    "                    attachment = True\n",
    "                else:\n",
    "                    attachment = False\n",
    "            data.append(x.get_payload()) \n",
    "            \n",
    "        if attachment:\n",
    "            email_attachment.append(1)\n",
    "        else:\n",
    "            email_attachment.append(0)\n",
    "                        \n",
    "                \n",
    "# Reference: https://gaurav.kuwar.us/index.php/2017/10/09/extracting-files-from-raw-email-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mail_types\"] = mail_ty\n",
    "df[\"text_types\"] = text_ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16dd7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count of mail types           \n",
    "df[\"mail_types\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of text types\n",
    "df[\"text_types\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with email text and target (whether mail is spam or not, 1 for spam and 0 for not a spam)\n",
    "email_df = pd.DataFrame()\n",
    "email_df[\"data\"] = data\n",
    "#email_df[\"mail_type\"] = mail_ty\n",
    "#email_df[\"text_type\"] = text_ty\n",
    "email_df[\"target\"] = target\n",
    "email_df[\"Attachments\"] = email_attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.loc[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b1e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df[\"data_new\"] = [''.join(str(item).lower()) for item in email_df.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(email_df[\"data_new\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the instanc of TfidfVectorizer\n",
    "#my_stop_words = text.ENGLISH_STOP_WORDS.union([\"spamassassin\", \"email\", \"message\", \"\\n\", \"nbsp\", \"font\",\"exhm\", \"subject\", \"list\", \"url\", \"net\"])\n",
    "from nltk.corpus import stopwords\n",
    "stop = list(stopwords.words('english'))\n",
    "stop.extend(\"spamassassin email message \\n nbsp font exhm subject list url net http www org html linux 2002 font e2 c2 div 0d c2 0a xa0 8c 2ffont e2 3e sourceforge  spamassasin 01 yahoo 1440 a0\".split())\n",
    "\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(analyzer = 'word',stop_words=set(stop))\n",
    "\n",
    "# tf_vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words=text.ENGLISH_STOP_WORDS)\n",
    "\n",
    "#tf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform email data\n",
    "new_vectors = tf_vectorizer.fit_transform(email_df.data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "plt.figure(figsize=(5,4))\n",
    "email_df.target.value_counts().plot.pie(autopct = \"%.1f%%\")\n",
    "plt.title(\"Proportion of Target Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df['Attachments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x =\"Attachments\", data = email_df)\n",
    "plt.title(\"Distribution of Attachments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x =\"Attachments\", hue = \"target\", data = email_df)\n",
    "plt.title(\"Attachments in Spam (1) vs Not Spam (0)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vectors = hstack((new_vectors,np.array(email_attachment)[:,None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f17f3a",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e3b1cc",
   "metadata": {},
   "source": [
    "#### KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bc7f3",
   "metadata": {},
   "source": [
    "K-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. Data points are clustered based on feature similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9259f",
   "metadata": {},
   "source": [
    "KMeans Clustering with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fc7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "score = []\n",
    "K = range(2,30)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=1234, init = 'k-means++')\n",
    "    km = km.fit(new_vectors)\n",
    "    labels = km.predict(new_vectors) \n",
    "    wcss.append(km.inertia_)\n",
    "    sc = silhouette_score(new_vectors, labels)\n",
    "    score.append(sc)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "#plt.subplot(1,1,1)\n",
    "plt.plot(K, wcss, 'bx-')\n",
    "plt.xlabel('Number of centroids')\n",
    "plt.ylabel('Within-Cluster-Sum-of-Squares')\n",
    "plt.title('Elbow Method For Optimal k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1c920",
   "metadata": {},
   "source": [
    "#### Visualize Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c421b0",
   "metadata": {},
   "source": [
    "We will use a technique called t-SNE (t-distributed Stochastic Neighbor Embedding) to generate a 2 dimensional representation of our dataset, in order to have a more intuitive understanding of how the clustering looks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf2b8a",
   "metadata": {},
   "source": [
    "First let's look at an un-clustered version of this 2D projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44399cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.cluster as cluster\n",
    "newdims = (12, 8)\n",
    "plt.subplots(1, 1, figsize=newdims)\n",
    "plt.subplot(1, 1, 1)\n",
    "plot_kwds = {'alpha' : 0.25, 's' : 40, 'linewidths':0}\n",
    "projection = TSNE().fit_transform(new_vectors)\n",
    "plt.scatter(*projection.T, **plot_kwds)\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a6917",
   "metadata": {},
   "source": [
    "Now look at clustered version of this 2D projection with various clustering techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b41180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import seaborn as sns\n",
    "\n",
    "# This function will run a given clustering algorithm and plot the clusters on the same 2D  TSNE projection as above\n",
    "def plot_clusters(data, algorithm, args, kwds):\n",
    "    labels = algorithm(*args, **kwds).fit_predict(data)\n",
    "    palette = sns.color_palette('muted', np.unique(labels).max() + 1)\n",
    "    colors = [palette[x] if x >= 0 else (.5, .5, .5) for x in labels]\n",
    "    plt.scatter(*projection.T, s=50, linewidth=0, c=colors, alpha=0.25)\n",
    "    frame = plt.gca()\n",
    "    frame.axes.get_xaxis().set_visible(True)\n",
    "    frame.axes.get_yaxis().set_visible(True)\n",
    "    #plot_kwds = {'alpha' : 0.25, 's' : 40, 'linewidths':0}\n",
    "    plt.title('Clusters found by {}'.format(str(algorithm.__name__)), fontsize=14)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4e71b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the clusters\n",
    "newdims = (10, 8)\n",
    "plt.subplots(1, 1, figsize=newdims)\n",
    "plt.subplot(1, 1, 1)\n",
    "plot_clusters(new_vectors, cluster.KMeans, (), {'n_clusters':best_k})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc5879",
   "metadata": {},
   "source": [
    "#### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8655adf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# word cloud with best K\n",
    "km = KMeans(n_clusters=best_k, init = 'k-means++')\n",
    "km = km.fit(new_vectors)\n",
    "labels = km.predict(new_vectors)\n",
    "    \n",
    "clusters = list(labels)\n",
    "\n",
    "kmeans_result={'cluster':clusters,'reviews':email_df.data_new}\n",
    "kmeans_result=pd.DataFrame(kmeans_result)\n",
    "for k in range(0,12):\n",
    "   s=kmeans_result[kmeans_result.cluster==k]\n",
    "   text=s['reviews'].str.cat(sep=' ')\n",
    "   text=text.lower()\n",
    "   text=' '.join([word for word in text.split()])\n",
    "   wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "   plt.figure()\n",
    "   plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "   plt.axis(\"off\")\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21f223",
   "metadata": {},
   "source": [
    "### Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb6e3b",
   "metadata": {},
   "source": [
    "It is a classification technique based on Bayesâ€™ Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayModel_metrics(best_model, grid_model, features, target, cv):\n",
    "    metrics = cross_validate(best_model, features, y=target, cv=cv, \n",
    "                             scoring=['accuracy','precision','recall'], return_train_score=True) \n",
    "    \n",
    "    y_predict = cross_val_predict(best_model, features, target, cv=cv)\n",
    "\n",
    "    print('\\nBest Accuracy with Grid Search            : {:.3f}'.format(grid_model.best_score_))\n",
    "    print('\\nTraining data Metrics')\n",
    "    print('\\n     The average accuraccy : {:.3f}'.format(metrics['train_accuracy'].mean()))\n",
    "    print('     The average precision : {:.3f}'.format(metrics['train_precision'].mean()))\n",
    "    print('     The average recall    : {:.3f}'.format(metrics['train_recall'].mean()))\n",
    "\n",
    "    print('\\nTest data Metrics')\n",
    "    print('\\n     The average accuracy  : {:.3f}'.format(metrics['test_accuracy'].mean()))\n",
    "    print('     The average precision : {:.3f}'.format(metrics['test_precision'].mean()))\n",
    "    print('     The average  recall   : {:.3f}'.format(metrics['test_recall'].mean()))\n",
    "    \n",
    "    matrix = classification_report(target, y_predict, labels=[1,0])\n",
    "    print('\\nClassification report\\n')\n",
    "    print(matrix)\n",
    "\n",
    "    \n",
    "    \n",
    "# Reference https://github.com/jakemdrew/DataMiningNotebooks/blob/master/06.%20Classification.ipynb\n",
    "# ROC curve plot\n",
    "def roc_curve_plot(model_fit, features, target):\n",
    "\n",
    "    sns.set_palette(\"dark\")\n",
    "\n",
    "    yhat_score = model_fit.predict_proba(features)\n",
    "\n",
    "    # Compute ROC curve for a subset of interesting classes\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in np.unique(target):\n",
    "        fpr[i], tpr[i], _ = mt.roc_curve(target, yhat_score[:, i], pos_label=i)\n",
    "        roc_auc[i] = mt.auc(fpr[i], tpr[i])\n",
    "\n",
    "    for i in np.unique(target):\n",
    "        plt.plot(fpr[i], tpr[i], label= ('class %d (area = %0.2f)' % (i, roc_auc[i])))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "    plt.legend(loc=\"lower right\")  \n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f126e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Cross Validation Procedure\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0eee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes (NB) classifier \n",
    "clf = MultinomialNB().fit(new_vectors,email_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605fafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "C_nb = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]  \n",
    "nb_prior=[True, False]\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "# define grid search\n",
    "param_grid_nb = dict(alpha=C_nb, fit_prior=nb_prior)\n",
    "\n",
    "grid_search_nb = GridSearchCV(estimator=nb_clf, param_grid=param_grid_nb, n_jobs=-1, cv=cv, \n",
    "                              scoring='accuracy',error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f247b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_result_nb = grid_search_nb.fit(new_vectors,email_df['target'])\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_nb.best_score_, grid_result_nb.best_params_))\n",
    "means = grid_result_nb.cv_results_['mean_test_score']\n",
    "stds = grid_result_nb.cv_results_['std_test_score']\n",
    "params = grid_result_nb.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GridSearch algorithm determined the following optimal parameters\n",
    "best_Estimator_nb =grid_result_nb.best_estimator_\n",
    "best_Estimator_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9777d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model metrics\n",
    "displayModel_metrics(best_Estimator_nb, grid_result_nb, new_vectors,email_df['target'], cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b567f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "roc_curve_plot(grid_result_nb, new_vectors, email_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8842f05",
   "metadata": {},
   "source": [
    "### Naive Bayes Classification with clusters as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed91ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clusters as feature\n",
    "new_vectors = hstack((new_vectors,np.array(clusters)[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aba5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_result_nb = grid_search_nb.fit(new_vectors,email_df['target'])\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_nb.best_score_, grid_result_nb.best_params_))\n",
    "means = grid_result_nb.cv_results_['mean_test_score']\n",
    "stds = grid_result_nb.cv_results_['std_test_score']\n",
    "params = grid_result_nb.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GridSearch algorithm determined the following optimal parameters\n",
    "best_Estimator_nb =grid_result_nb.best_estimator_\n",
    "best_Estimator_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5310c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model metrics\n",
    "displayModel_metrics(best_Estimator_nb, grid_result_nb, new_vectors,email_df['target'], cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b640c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "roc_curve_plot(grid_result_nb, new_vectors, email_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed502c1",
   "metadata": {},
   "source": [
    "### Feature importance with Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f32bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "\n",
    "# define parameters\n",
    "penalty_LR = ['l1', 'l2', 'elasticnet', 'none'] \n",
    "#penalty_LR = [ 'l1', 'l2'] \n",
    "C_LR = [0.001, 0.01, 0.1, 1, 10, 100, 1000]  \n",
    "#C_LR = [0.001,10, 100]  \n",
    "max_iter_LR = [500]\n",
    "#max_iter_LR = [500]\n",
    "class_weight_LR = ['balanced']\n",
    "#solver_LR = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "solver_LR = ['lbfgs', 'liblinear']\n",
    "\n",
    "# define grid search\n",
    "param_grid_LR = dict(penalty=penalty_LR, C=C_LR, max_iter=max_iter_LR, class_weight=class_weight_LR, solver=solver_LR)\n",
    "\n",
    "grid_search_LR = GridSearchCV(estimator=LR, param_grid=param_grid_LR, n_jobs=-1, cv=cv, \n",
    "                              scoring='accuracy',error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_result_LR = grid_search_LR.fit(new_vectors,email_df['target'])\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_LR.best_score_, grid_result_LR.best_params_))\n",
    "means = grid_result_LR.cv_results_['mean_test_score']\n",
    "stds = grid_result_LR.cv_results_['std_test_score']\n",
    "params = grid_result_LR.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GridSearch algorithm determined the following optimal parameters\n",
    "best_Estimator_LR =grid_result_LR.best_estimator_\n",
    "best_Estimator_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2545a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf_vectorizer.get_feature_names()\n",
    "features.append('email_attachment')\n",
    "features.append('clusters')\n",
    "\n",
    "feature_importance_df = pd.DataFrame(features, columns=['features'])\n",
    "feature_importance_df['feature_coef'] = best_Estimator_LR.coef_[0]\n",
    "\n",
    "feature_importance_df.head()\n",
    "feature_importance_df = feature_importance_df.sort_values(by=['feature_coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a93e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ff220",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2de6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
